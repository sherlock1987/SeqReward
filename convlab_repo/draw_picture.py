import seaborn as sns
import numpy as np
from numpy.random import randn
import matplotlib.pyplot as plot
from matplotlib.ticker import FuncFormatter
from matplotlib.ticker import MultipleLocator, FormatStrFormatter
from matplotlib.backends.backend_pdf import PdfPages

def kl_divergence(reward_pos, reward_neg):
    """
    Two list
    Returns: one number(float)
    """
    reward_pos = np.array(reward_pos)
    reward_neg = np.array(reward_neg)

    di = reward_pos/reward_neg
    di = np.log(di)
    di *= reward_pos
    kl = np.sum(di)
    return kl

def js_divergence(reward_pos, reward_neg):
    reward_pos = np.array(reward_pos)
    reward_neg = np.array(reward_neg)
    return (kl_divergence(reward_pos, reward_neg)+kl_divergence(reward_neg, reward_pos))/2

reward_pos = [0.7818140387535095, 0.8499061465263367, 0.926633358001709, 0.9345168471336365, 0.7372043132781982, 0.12733350694179535, 0.8537020087242126, 0.8534179329872131, 0.832329273223877, 0.8182196021080017, 0.7892539501190186, 0.162649467587471, 0.932776153087616, 0.932776153087616, 0.8594306111335754, 0.8695045113563538, 0.8441696166992188, 0.816753089427948, 0.7654871940612793, 0.8508231043815613, 0.8553133606910706, 0.9172642230987549, 0.8111723065376282, 0.8284408450126648, 0.9290274977684021, 0.7648630142211914, 0.618450403213501, 0.7059414386749268, 0.8703122735023499, 0.7616555094718933, 0.8152179718017578, 0.7611947655677795, 0.7676019668579102, 0.8029031753540039, 0.9442186951637268, 0.9442186951637268, 0.7926897406578064, 0.4059222638607025, 0.8818728923797607, 0.829338550567627, 0.7952554821968079, 0.7793654799461365, 0.9271240234375, 0.8580923676490784, 0.728967010974884, 0.7974061369895935, 0.05208520218729973, 0.5610266327857971, 0.8862481713294983, 0.4125799238681793, 0.8922488689422607, 0.931948721408844, 0.4152723550796509, 0.9171991944313049, 0.841637909412384, 0.36083701252937317, 0.7542094588279724, 0.8720318675041199, 0.7399635314941406, 0.8479228019714355, 0.9415457248687744, 0.8184413909912109, 0.8606622815132141, 0.8085241317749023, 0.9284945130348206, 0.7279478907585144, 0.3323327898979187, 0.9166737198829651, 0.9069528579711914, 0.9159989953041077, 0.915078341960907, 0.8437764048576355, 0.9112547039985657, 0.3482341766357422, 0.6472391486167908, 0.8228392601013184, 0.8427560329437256, 0.6260867714881897, 0.9004082679748535, 0.8014357686042786, 0.8675710558891296, 0.8077619671821594, 0.8765182495117188, 0.9297149777412415, 0.7849712371826172, 0.849456250667572, 0.5156157612800598, 0.7450323700904846, 0.7443411350250244, 0.9197428226470947, 0.8312661051750183, 0.8600392937660217, 0.8434475064277649, 0.8125386238098145, 0.14804202318191528, 0.9155591130256653, 0.782271683216095, 0.8449528217315674, 0.859013020992279, 0.8116948008537292]
reward_neg = [0.7818140387535095, 0.8499061465263367, 0.926633358001709, 0.9345168471336365, 0.7372043132781982, 0.12733350694179535, 0.8537020087242126, 0.8534179329872131, 0.832329273223877, 0.8182196021080017, 0.7892539501190186, 0.162649467587471, 0.932776153087616, 0.932776153087616, 0.8594306111335754, 0.8695045113563538, 0.8441696166992188, 0.816753089427948, 0.7654871940612793, 0.8508231043815613, 0.8553133606910706, 0.9172642230987549, 0.8111723065376282, 0.8284408450126648, 0.9290274977684021, 0.7648630142211914, 0.618450403213501, 0.7059414386749268, 0.8703122735023499, 0.7616555094718933, 0.8152179718017578, 0.7611947655677795, 0.7676019668579102, 0.8029031753540039, 0.9442186951637268, 0.9442186951637268, 0.7926897406578064, 0.4059222638607025, 0.8818728923797607, 0.829338550567627, 0.7952554821968079, 0.7793654799461365, 0.9271240234375, 0.8580923676490784, 0.728967010974884, 0.7974061369895935, 0.05208520218729973, 0.5610266327857971, 0.8862481713294983, 0.4125799238681793, 0.8922488689422607, 0.931948721408844, 0.4152723550796509, 0.9171991944313049, 0.841637909412384, 0.36083701252937317, 0.7542094588279724, 0.8720318675041199, 0.7399635314941406, 0.8479228019714355, 0.9415457248687744, 0.8184413909912109, 0.8606622815132141, 0.8085241317749023, 0.9284945130348206, 0.7279478907585144, 0.3323327898979187, 0.9166737198829651, 0.9069528579711914, 0.9159989953041077, 0.915078341960907, 0.8437764048576355, 0.9112547039985657, 0.3482341766357422, 0.6472391486167908, 0.8228392601013184, 0.8427560329437256, 0.6260867714881897, 0.9004082679748535, 0.8014357686042786, 0.8675710558891296, 0.8077619671821594, 0.8765182495117188, 0.9297149777412415, 0.7849712371826172, 0.849456250667572, 0.5156157612800598, 0.7450323700904846, 0.7443411350250244, 0.9197428226470947, 0.8312661051750183, 0.8600392937660217, 0.8434475064277649, 0.8125386238098145, 0.14804202318191528, 0.9155591130256653, 0.782271683216095, 0.8449528217315674, 0.859013020992279, 0.8116948008537292]

reward_pos = np.array(reward_pos)
reward_neg = np.array(reward_neg)

reward_pos*=100

fig = plot.figure()

ax = fig.add_subplot(1, 1, 1)

plot.hist(reward_pos, bins = 10, density= True)
ax.set_xticks([0, 25, 50, 75, 100])
ax.set_xticklabels(['0', '0.25', '0.5', '0.75','1'])

print(kl_divergence(reward_pos/100, reward_neg))
# sns.displot(reward_pos, kde = False, hue_norm = True, bins= 100)
plot.title("Distribution of Fake and Real Data")
plot.xlabel("Score")
plot.ylabel("Frequency")
plot.legend()
plot.show()

